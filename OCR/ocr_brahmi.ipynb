{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 0 a(3) 1 a(4) 2 a(5) 3 aaa 4 ba 5 ba(2) 6 baa 7 be 8 bha 9 bhaa 10 bhe 11 bhi 12 bhii 13 bho 14 bhu 15 bhuu 16 bi 17 bii 18 bo 19 bo(2) 20 bu 21 buu 22 ca 23 caa 24 ce 25 cha 26 chaa 27 che 28 chi 29 chii 30 cho 31 chu 32 chuu 33 ci 34 cii 35 co 36 cu 37 cuu 38 da(2) 39 daa 40 daa(2) 41 daaa 42 daaaa 43 dae 44 dai 45 daii 46 dao 47 dau 48 dauu 49 de 50 dha 51 dhaa 52 dhaaa 53 dhaaaa 54 dhae 55 dhai 56 dhaii 57 dhao 58 dhau 59 dhauu 60 dhi 61 dhii 62 dho 63 dhu 64 dhue 65 dhuu 66 di 67 dii 68 do 69 du 70 duu 71 e 72 ee 73 ga 74 gaa 75 ge 76 gha 77 ghaa 78 ghe 79 ghi 80 ghii 81 gho 82 ghu 83 ghuu 84 gi 85 gii 86 go 87 gu 88 guu 89 ha 90 haa 91 he 92 hi 93 hii 94 ho 95 hu 96 huu 97 i 98 ja 99 ja(2) 100 ja(3) 101 ja(4) 102 jaa 103 je 104 jha 105 jhaa 106 jhe 107 jhi 108 jhii 109 jho 110 jhu 111 jhuu 112 ji 113 jii 114 jo 115 ju 116 juu 117 ka 118 kaa 119 ke 120 kha 121 kha(2) 122 khaa 123 khaa(2) 124 khe 125 khe(2) 126 khi 127 khii 128 khii(2) 129 kho 130 kho(2) 131 khu 132 khu(2) 133 khuu 134 khuu(2) 135 ki 136 kii 137 ko 138 ku 139 kuu 140 la 141 la(2) 142 la(3) 143 laa 144 le 145 li 146 lii 147 lo 148 lu 149 luu 150 ma 151 ma(2) 152 maa 153 me 154 mi 155 mii 156 mo 157 mu 158 muu 159 na 160 na(2) 161 naa 162 ne 163 ni 164 nii 165 nna 166 nnaa 167 nne 168 nni 169 nnii 170 nno 171 nno(2) 172 nnu 173 nnuu 174 no 175 nu 176 nuu 177 nya 178 nya(2) 179 o 180 o(2) 181 pa 182 paa 183 pe 184 pha 185 pha(2) 186 phaa 187 phe 188 phi 189 phii 190 pho 191 phu 192 phuu 193 pi 194 pii 195 po 196 pu 197 puu 198 ra 199 ra(2) 200 ra(3) 201 raa 202 re 203 ri 204 rii 205 ro 206 ru 207 ruu 208 sa 209 sa(2) 210 saa 211 se 212 sha 213 shaa 214 shaaa 215 shaaaa 216 shae 217 shai 218 shaii 219 shao 220 shau 221 she 222 shi 223 shii 224 sho 225 shu 226 shuu 227 si 228 sii 229 so 230 su 231 suu 232 ta 233 taa 234 taaa 235 taaaa 236 tae 237 tai 238 taii 239 tao 240 tau 241 tauu 242 te 243 tha 244 tha(2) 245 thaa 246 thaaa 247 thaaaa 248 thaai 249 thae 250 thai 251 thaii 252 thao 253 thau 254 thauu 255 the 256 the(2) 257 thi 258 thii 259 tho 260 thu 261 thuu 262 tii 263 to 264 tu 265 tuu 266 va 267 vaa 268 vhu 269 vhuu 270 vi 271 vii 272 vu 273 vu(2) 274 vuu 275 vuu(2) 276 ya 277 ya(2) 278 yaa 279 ye 280 yi 281 yii 282 yo 283 yo(2) 284 yu 285 yuu 286 "
     ]
    }
   ],
   "source": [
    "#Adding all images to one list with classes into another.\n",
    "\n",
    "dataset_path = 'OCR_Dataset\\RecognizerDataset_150_210'\n",
    "images = []\n",
    "class_ids = []\n",
    "dirs = os.listdir(dataset_path)\n",
    "no_of_classes = len(dirs)\n",
    "class_id_counter = 0\n",
    "for class_id in dirs:\n",
    "    imageList = os.listdir(os.path.join(dataset_path, str(class_id)))\n",
    "    for image_name in imageList:\n",
    "        curImg = cv2.imread(os.path.join(dataset_path, str(class_id), str(image_name)))\n",
    "        curImg = cv2.resize(curImg, (32,32))\n",
    "        images.append(curImg)\n",
    "        class_ids.append(class_id_counter)\n",
    "    print(class_id , class_id_counter, end= \" \")\n",
    "    class_id_counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60048, 32, 32, 3)\n",
      "(60048,)\n"
     ]
    }
   ],
   "source": [
    "images = np.array(images)\n",
    "class_ids = np.array(class_ids)\n",
    "print(images.shape)\n",
    "print(class_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : (38430, 32, 32, 3)\n",
      "Testing : (12010, 32, 32, 3)\n",
      "Validation : (9608, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#Train test split\n",
    "test_ratio = 0.2\n",
    "validation_ratio = 0.2\n",
    "X_train, X_test, y_train, y_test =train_test_split(images, class_ids, test_size=test_ratio)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_ratio)\n",
    "print(\"Training : \" + str(X_train.shape))\n",
    "print(\"Testing : \" + str(X_test.shape))\n",
    "print(\"Validation : \" + str(X_validation.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate(img):\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    return cv2.dilate(img, kernel, iterations=1)\n",
    "\n",
    "\n",
    "X_train = np.array(list(map(dilate, X_train)))\n",
    "X_test = np.array(list(map(dilate, X_test)))\n",
    "X_validation = np.array(list(map(dilate, X_validation)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "(32, 32)\n",
      "(32, 32)\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing\n",
    "def pre_process(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    img = img/255\n",
    "    return img\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\" img = pre_process(X_train[45])\n",
    "img = cv2.resize(img, (300, 300))\n",
    "cv2.imshow(\"PreProcessed\", img)\n",
    "cv2.waitKey(0) \"\"\"\n",
    "\n",
    "X_train = np.array(list(map(pre_process, X_train)))\n",
    "X_test = np.array(list(map(pre_process, X_test)))\n",
    "X_validation = np.array(list(map(pre_process, X_validation)))\n",
    "\n",
    "print(X_train[45])\n",
    "print(X_test[45].shape)\n",
    "print(X_validation[45].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38430, 32, 32)\n",
      "(32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "#Adding depth of 1 for NN\n",
    "print(X_train.shape)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "X_validation = X_validation.reshape(X_validation.shape[0], X_validation.shape[1], X_validation.shape[2], 1)\n",
    "print(X_train[45].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndataGen = ImageDataGenerator(width_shift_range=0.05, height_shift_range=0.05, zoom_range=0.1, shear_range=0.1,rotation_range=5)\\ndataGen.fit(X_train)'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "'''\n",
    "dataGen = ImageDataGenerator(width_shift_range=0.05, height_shift_range=0.05, zoom_range=0.1, shear_range=0.1,rotation_range=5)\n",
    "dataGen.fit(X_train)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#Converting to one-hot encoding\n",
    "y_train = to_categorical(y_train, no_of_classes)\n",
    "y_test = to_categorical(y_test, no_of_classes)\n",
    "y_validation = to_categorical(y_validation, no_of_classes)\n",
    "\n",
    "print(y_train[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 60)        1560      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 60)        90060     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 10, 10, 30)        16230     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 30)          8130      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 30)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 30)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               240500    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 287)               143787    \n",
      "=================================================================\n",
      "Total params: 500,267\n",
      "Trainable params: 500,267\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Model\n",
    "def myModel():\n",
    "    no_of_filters = 60\n",
    "    size_of_filter1 = (5,5)\n",
    "    size_of_filter2 = (3,3)\n",
    "    size_of_pool = (2,2)\n",
    "    no_of_nodes = 500\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add((Conv2D(no_of_filters, size_of_filter1, input_shape = (32,32,1), activation='relu')))\n",
    "    model.add((Conv2D(no_of_filters, size_of_filter1, activation='relu')))\n",
    "    model.add(MaxPooling2D(pool_size=size_of_pool))\n",
    "    model.add((Conv2D(no_of_filters//2, size_of_filter2, activation='relu')))\n",
    "    model.add((Conv2D(no_of_filters//2, size_of_filter2, activation='relu')))\n",
    "    model.add(MaxPooling2D(pool_size=size_of_pool))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(no_of_nodes, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(no_of_classes, activation='softmax'))\n",
    "    model.compile('adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = myModel()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38430 samples, validate on 9608 samples\n",
      "Epoch 1/25\n",
      "38430/38430 [==============================] - 112s 3ms/step - loss: 5.6611 - accuracy: 0.0033 - val_loss: 5.6614 - val_accuracy: 0.0026\n",
      "Epoch 2/25\n",
      "38430/38430 [==============================] - 112s 3ms/step - loss: 5.5740 - accuracy: 0.0104 - val_loss: 5.4441 - val_accuracy: 0.0220\n",
      "Epoch 3/25\n",
      "38430/38430 [==============================] - 108s 3ms/step - loss: 5.4037 - accuracy: 0.0235 - val_loss: 5.3249 - val_accuracy: 0.0348\n",
      "Epoch 4/25\n",
      "38430/38430 [==============================] - 115s 3ms/step - loss: 5.3226 - accuracy: 0.0317 - val_loss: 5.2828 - val_accuracy: 0.0401\n",
      "Epoch 5/25\n",
      "38430/38430 [==============================] - 116s 3ms/step - loss: 5.2754 - accuracy: 0.0376 - val_loss: 5.2384 - val_accuracy: 0.0490\n",
      "Epoch 6/25\n",
      "38430/38430 [==============================] - 105s 3ms/step - loss: 5.2389 - accuracy: 0.0434 - val_loss: 5.2063 - val_accuracy: 0.0584\n",
      "Epoch 7/25\n",
      "38430/38430 [==============================] - 106s 3ms/step - loss: 5.2134 - accuracy: 0.0462 - val_loss: 5.1832 - val_accuracy: 0.0586\n",
      "Epoch 8/25\n",
      "38430/38430 [==============================] - 113s 3ms/step - loss: 5.1926 - accuracy: 0.0499 - val_loss: 5.1555 - val_accuracy: 0.0619\n",
      "Epoch 9/25\n",
      "38430/38430 [==============================] - 109s 3ms/step - loss: 5.1663 - accuracy: 0.0542 - val_loss: 5.1355 - val_accuracy: 0.0649\n",
      "Epoch 10/25\n",
      "38430/38430 [==============================] - 108s 3ms/step - loss: 5.1519 - accuracy: 0.0560 - val_loss: 5.1149 - val_accuracy: 0.0681\n",
      "Epoch 11/25\n",
      "38430/38430 [==============================] - 114s 3ms/step - loss: 5.1350 - accuracy: 0.0594 - val_loss: 5.0995 - val_accuracy: 0.0744\n",
      "Epoch 12/25\n",
      "38430/38430 [==============================] - 114s 3ms/step - loss: 5.1152 - accuracy: 0.0622 - val_loss: 5.0795 - val_accuracy: 0.0749\n",
      "Epoch 13/25\n",
      "38430/38430 [==============================] - 111s 3ms/step - loss: 5.0944 - accuracy: 0.0643 - val_loss: 5.0722 - val_accuracy: 0.0750\n",
      "Epoch 14/25\n",
      "38430/38430 [==============================] - 117s 3ms/step - loss: 5.0784 - accuracy: 0.0676 - val_loss: 5.0437 - val_accuracy: 0.0808\n",
      "Epoch 15/25\n",
      "38430/38430 [==============================] - 116s 3ms/step - loss: 5.0683 - accuracy: 0.0678 - val_loss: 5.0330 - val_accuracy: 0.0805\n",
      "Epoch 16/25\n",
      "38430/38430 [==============================] - 115s 3ms/step - loss: 5.0487 - accuracy: 0.0700 - val_loss: 5.0215 - val_accuracy: 0.0825\n",
      "Epoch 17/25\n",
      "38430/38430 [==============================] - 115s 3ms/step - loss: 5.0436 - accuracy: 0.0717 - val_loss: 5.0089 - val_accuracy: 0.0847\n",
      "Epoch 18/25\n",
      "38430/38430 [==============================] - 108s 3ms/step - loss: 5.0356 - accuracy: 0.0716 - val_loss: 5.0036 - val_accuracy: 0.0860\n",
      "Epoch 19/25\n",
      "38430/38430 [==============================] - 103s 3ms/step - loss: 5.0167 - accuracy: 0.0760 - val_loss: 4.9933 - val_accuracy: 0.0873\n",
      "Epoch 20/25\n",
      "38430/38430 [==============================] - 102s 3ms/step - loss: 5.0081 - accuracy: 0.0762 - val_loss: 4.9881 - val_accuracy: 0.0896\n",
      "Epoch 21/25\n",
      "38430/38430 [==============================] - 104s 3ms/step - loss: 5.0020 - accuracy: 0.0771 - val_loss: 4.9733 - val_accuracy: 0.0896\n",
      "Epoch 22/25\n",
      "38430/38430 [==============================] - 106s 3ms/step - loss: 4.9901 - accuracy: 0.0798 - val_loss: 4.9621 - val_accuracy: 0.0937\n",
      "Epoch 23/25\n",
      "38430/38430 [==============================] - 107s 3ms/step - loss: 4.9851 - accuracy: 0.0810 - val_loss: 4.9611 - val_accuracy: 0.0938\n",
      "Epoch 24/25\n",
      "38430/38430 [==============================] - 108s 3ms/step - loss: 4.9752 - accuracy: 0.0827 - val_loss: 4.9626 - val_accuracy: 0.0934\n",
      "Epoch 25/25\n",
      " 9312/38430 [======>.......................] - ETA: 1:20 - loss: 4.9686 - accuracy: 0.0796"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14328\\4043818120.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Without augmentation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# With augmentation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\PranavRajnish\\anaconda3\\envs\\OCR\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mc:\\Users\\PranavRajnish\\anaconda3\\envs\\OCR\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\PranavRajnish\\anaconda3\\envs\\OCR\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\PranavRajnish\\anaconda3\\envs\\OCR\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\PranavRajnish\\anaconda3\\envs\\OCR\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\PranavRajnish\\anaconda3\\envs\\OCR\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\PranavRajnish\\anaconda3\\envs\\OCR\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\PranavRajnish\\anaconda3\\envs\\OCR\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "epochs_val = 25\n",
    "batch_size_val = 50\n",
    "steps_per_epoch_val = 38000//batch_size_val\n",
    "validation_steps_val = 2000\n",
    "\n",
    "#history = model.fit(X_train, y_train, batch_size=batch_size_val, epochs=epochs_val, steps_per_epoch=steps_per_epoch_val, validation_steps=validation_steps_val, validation_data=(X_validation, y_validation), shuffle=1)\n",
    "\n",
    "# Without augmentation\n",
    "history = model.fit(X_train, y_train, epochs=epochs_val, validation_data=(X_validation, y_validation), shuffle=1)\n",
    "\n",
    "# With augmentation\n",
    "#history = model.fit_generator(dataGen.flow(X_train, y_train, batch_size=batch_size_val),  steps_per_epoch=steps_per_epoch_val, epochs=epochs_val, validation_data=(X_validation, y_validation), shuffle=1)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Score =', score[0])\n",
    "print('Test Accuracy =', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"ocr_model_trained_with_dilation\", \"wb\")\n",
    "pickle.dump(model, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 32, 32, 1)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Test Score = 3.389374007119073\n",
      "Test Accuracy = 0.2888889014720917\n",
      "phuu\n",
      "aaa\n",
      "haa\n",
      "bhe\n",
      "thuu\n",
      "buu\n",
      "thuu\n",
      "che\n",
      "chu\n",
      "taii\n",
      "a\n",
      "muu\n",
      "le\n",
      "ro\n",
      "thai\n",
      "dhi\n",
      "raa\n",
      "ghu\n",
      "pi\n",
      "gaa\n",
      "haa\n",
      "dauu\n",
      "ro\n",
      "ke\n",
      "kho\n",
      "aaa\n",
      "thaii\n",
      "ro\n",
      "nnu\n",
      "nnii\n",
      "o\n",
      "paa\n",
      "pe\n",
      "phuu\n",
      "re\n",
      "re\n",
      "khii\n",
      "shai\n",
      "she\n",
      "sii\n",
      "so\n",
      "jhi\n",
      "te\n",
      "thauu\n",
      "ya\n"
     ]
    }
   ],
   "source": [
    "Capstone_Handwritten_Letters_Path = \"C:\\MyStuff\\PES\\Capstone_Handwritten_Letters\"\n",
    "test_images = []\n",
    "test_class_ids = []\n",
    "dir_to_num = {}\n",
    "num_to_name = {}\n",
    "class_id_counter = 0\n",
    "\n",
    "for class_id in dirs:\n",
    "        dir_to_num[class_id] = class_id_counter\n",
    "        num_to_name[class_id_counter] = class_id\n",
    "        class_id_counter+=1\n",
    "\n",
    "imageList = os.listdir(Capstone_Handwritten_Letters_Path)\n",
    "for image_name in imageList:\n",
    "        curImg = cv2.imread(os.path.join(Capstone_Handwritten_Letters_Path, str(image_name)))\n",
    "        curImg = cv2.resize(curImg, (32,32))\n",
    "        test_images.append(curImg)\n",
    "        test_class_ids.append(dir_to_num[image_name[:-4]])\n",
    "        \n",
    "test_images = np.array(test_images)\n",
    "test_class_ids = np.array(test_class_ids)\n",
    "\n",
    "test_images = np.array(list(map(pre_process, test_images)))\n",
    "\n",
    "test_images = test_images.reshape(test_images.shape[0], test_images.shape[1], test_images.shape[2], 1)\n",
    "print(test_images.shape)\n",
    "test_class_ids = to_categorical(test_class_ids, no_of_classes)\n",
    "\n",
    "score = model.evaluate(test_images, test_class_ids, verbose=0)\n",
    "print('Test Score =', score[0])\n",
    "print('Test Accuracy =', score[1]) \n",
    "\n",
    "'''\n",
    "predictions = model.predict(test_images)\n",
    "predictions = np.array(predictions)\n",
    "print(predictions.shape)\n",
    "print(len(predictions[0]))\n",
    "\n",
    "test_preds = []\n",
    "for pred in predictions:\n",
    "        max_val = -1\n",
    "        index_val = -1\n",
    "        for idx, val in enumerate(pred):\n",
    "                if val > max_val:\n",
    "                        max_val = val\n",
    "                        index_val = idx\n",
    "\n",
    "        test_preds.append(num_to_name[index_val])\n",
    "'''\n",
    "predictions = model.predict_classes(test_images)\n",
    "for pred in predictions:\n",
    "        print(num_to_name[pred])\n",
    "#print(test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('OCR')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8d1e289166fd3ce52eef0b2e4b5c218378e97c39b4150dffd6c9c74a550c5a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
